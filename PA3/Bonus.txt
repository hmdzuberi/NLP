While TF-IDF is often effective for text classification, it’s usually not the best fit for Naive Bayes classifiers. That’s because Naive Bayes is designed around binary or frequency-based data rather than weighted values.
Binary or frequency representations align naturally with Naive Bayes’ probabilistic assumptions, so they typically yield better performance. Switching to TF-IDF with Naive Bayes doesn't improve accuracy (as seen in ) because TF-IDF doesn’t match well with the underlying assumptions of the algorithm. To effectively leverage TF-IDF, you’d generally choose a different type of classifier instead.